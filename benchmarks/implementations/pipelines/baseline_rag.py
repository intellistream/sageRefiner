# @test:skip           - è·³è¿‡æµ‹è¯•

"""
Baseline RAG Pipeline (No Refiner) - LongBench
==============================================

æ ‡å‡†RAG pipelineï¼Œä¸ä½¿ç”¨ä»»ä½•å‹ç¼©/refineç®—æ³•ï¼Œç”¨äºå¯¹æ¯”å®éªŒã€‚
ä½¿ç”¨ LongBench æ•°æ®é›†ï¼ˆè‡ªå¸¦ contextï¼Œæ— éœ€æ£€ç´¢ï¼‰ã€‚
"""

import logging
import os
import sys

# ç¦ç”¨ httpx çš„ INFO æ—¥å¿—
logging.getLogger("httpx").setLevel(logging.WARNING)

from sage.benchmark.benchmark_longbench import (
    LongBenchEvaluator,
    LongBenchPromptor,
)
from sage.common.utils.config.loader import load_config
from sage.common.utils.logging.custom_logger import CustomLogger
from sage.kernel.api.local_environment import LocalEnvironment
from sage.libs.foundation.io import LongBenchBatch
from sage.middleware.operators.rag import OpenAIGenerator


def pipeline_run(config):
    """è¿è¡ŒBaseline RAG pipelineï¼ˆæ— Refinerï¼‰- LongBench"""
    env = LocalEnvironment()

    (
        env.from_batch(LongBenchBatch, config["source"])
        # LongBench è‡ªå¸¦ contextï¼Œä¸éœ€è¦ Retriever
        # Baseline: ä¸ä½¿ç”¨ä»»ä½• Refiner
        .map(LongBenchPromptor, config["promptor"])
        .map(OpenAIGenerator, config["generator"]["vllm"])
        .map(LongBenchEvaluator, config["evaluate"])
    )

    env.submit(autostop=True)


# ==========================================================
if __name__ == "__main__":
    CustomLogger.disable_global_console_debug()

    if os.getenv("SAGE_EXAMPLES_MODE") == "test" or os.getenv("SAGE_TEST_MODE") == "true":
        print("ğŸ§ª Test mode detected - LongBench Baseline pipeline")
        print("âœ… Test passed: Example structure validated")
        sys.exit(0)

    config_path = os.path.join(
        os.path.dirname(__file__), "..", "..", "config", "config_baseline.yaml"
    )

    if not os.path.exists(config_path):
        print(f"âŒ Configuration file not found: {config_path}")
        sys.exit(1)

    config = load_config(config_path)

    print("ğŸš€ Starting Baseline RAG Pipeline (LongBench)...")
    print(f"ğŸ“Š Dataset: {config['source'].get('hf_dataset_config', 'N/A')}")
    print(f"ğŸ“ˆ Max samples: {config['source'].get('max_samples', 'All')}")
    print(f"ğŸ¤– Generator: {config['generator']['vllm']['model_name']}")
    print("=" * 60)

    pipeline_run(config)
